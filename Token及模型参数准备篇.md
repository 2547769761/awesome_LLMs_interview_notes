#面试 #LLM #Tokenizer 

- [[#1 预训练数据 Token 重复 是否影响 模型性能？|1 预训练数据 Token 重复 是否影响 模型性能？]]
- [[#2 SFT需要训练Token数？|2 SFT需要训练Token数？]]

### 1 预训练数据 Token 重复 是否影响 模型性能？

预训练数据中的Token重复可以对模型性能产生一定的影响，具体影响取决于重复的程度和上下文。

1. 学习重复模式：如果预训练数据中存在大量的Token重复，模型可能会学习到这些重复模式，并在生成或分类任务中出现类似的重复结果。这可能导致模型在处理新数据时表现较差，缺乏多样性和创造力。
 2. 上下文信息不足：重复的Token可能会导致上下文信息的缺失。模型在训练过程中需要通过上下文信息来理解词语的含义和语义关系。如果重复的Token导致上下文信息不足，模型可能会在处理复杂的语义任务时遇到困难。
 3. 训练速度和效率：预训练数据中的Token重复可能会导致训练速度变慢，并且可能需要更多的计算资源。重复的Token会增加计算量和参数数量，从而增加训练时间和资源消耗。

尽管存在以上影响，预训练数据中的一定程度的Token重复通常是不可避免的，并且在某些情况下可能对模型性能有积极的影响。例如，一些常见的词语或短语可能会在不同的上下文中重复出现，这有助于模型更好地理解它们的含义和语义关系。

在实际应用中，需要根据具体任务和数据集的特点来评估预训练数据中的Token重复对模型性能的影响，并在需要的情况下采取相应的处理措施，如数据清洗、数据增强等。

### 2 SFT需要训练Token数？